import torch
import torch.nn as nn
import torch.nn.functional as F
import cutlass_gemm_with_prefetch
import time
import itertools
import pandas as pd
from dataclasses import dataclass
from typing import List, Tuple, Dict, Optional
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import json

class FeedForwardPDLConfig:
    def __init__(self):
        self.mm1_overlap_ratio = 0.0
        self.mm1_prefetch_ratio = 0.0
        self.mm2_overlap_ratio = 0.0
        self.mm2_prefetch_ratio = 0.0
        self.rmsnorm_prefetch_ratio = 0.0
        self.rmsnorm_overlap_ratio = 0.0
        self.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.NONE

class FeedForward(nn.Module):
    def __init__(self, K, N, config):
        super().__init__()
        self.weight1 = torch.normal(0, 1, size=(K, N)).to(device="cuda").to(dtype=torch.float8_e5m2)
        self.weight2 = torch.normal(0, 1, size=(N, K)).to(device="cuda").to(dtype=torch.float8_e5m2)
        self.config = config
        self.activation_type = "rmsnorm"
        self.first_call = True
        self.D = None
        self.rmsnorm_weight = None
        
    def init_weight(self, x):
        if self.first_call:
            self.D = torch.normal(0, 1, size=x.shape).to(device="cuda").to(dtype=torch.float8_e4m3fn)
            self.rmsnorm_weight = torch.normal(0, 1, size=(x.shape[-1],)).to(device="cuda").to(dtype=torch.float8_e4m3fn)
            self.first_call = False

    def forward(self, x):
        self.init_weight(x)
        x = cutlass_gemm_with_prefetch.mm(x, self.weight1, x, self.D, 
                                         self.config.mm1_overlap_ratio, 
                                         self.config.mm1_prefetch_ratio)
        x = cutlass_gemm_with_prefetch.rmsnorm(x, x, self.rmsnorm_weight, 
                                              self.config.rmsnorm_prefetch_ratio, 
                                              self.config.hierarchy)
        x = cutlass_gemm_with_prefetch.mm(x, self.weight2, x, self.D, 
                                         self.config.mm2_overlap_ratio, 
                                         self.config.mm2_prefetch_ratio)
        return x

@dataclass
class DetailedTestResult:
    """å­˜å‚¨æ¯ä¸ªæµ‹è¯•çš„è¯¦ç»†ç»“æœ"""
    shape: Tuple[int, int, int]  # (M, K, N)
    hierarchy: str
    mm1_overlap_ratio: float
    mm1_prefetch_ratio: float
    mm2_overlap_ratio: float
    mm2_prefetch_ratio: float
    rmsnorm_prefetch_ratio: float
    latency_ms: float
    throughput_gflops: float
    latency_std_ms: float  # å»¶è¿Ÿæ ‡å‡†å·®
    successful: bool
    error_msg: str
    timestamp: str
    
    # é¢å¤–çš„ç»Ÿè®¡ä¿¡æ¯
    min_latency_ms: float
    max_latency_ms: float
    median_latency_ms: float

class ComprehensiveFFNTester:
    def __init__(self):
        # å®šä¹‰æ›´å¯†é›†çš„æµ‹è¯•èŒƒå›´
        # MMç›¸å…³çš„ratio: åŒ…å«æ›´å¤šä¸­é—´å€¼
        self.mm_ratio_values = [  0.5, 0.0, 0.1, 0.2, 0.3, 0.4,-1.0, 0.6, 0.7, 0.8, 0.9, 1.0]
        # RMSNormçš„ratio: æ›´ç»†ç²’åº¦
        self.rmsnorm_ratio_values = [0.4,0.0, 0.1, 0.2, 0.3,  0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        
        # æµ‹è¯•çš„shapes
        self.test_shapes = [
            # (1024, 1024, 2048),
            # (2048, 1024, 2048),
            # (4096, 1024, 2048),
            (1024, 2048, 4096),
            # (2048, 2048, 4096),
            # (1024, 4096, 8192),
            (512, 512, 1024),    # å°shape
            # (8192, 1024, 2048),  # å¤§shape
        ]
        
        self.warmup_iters = 20
        self.test_iters = 100
        self.test_count = 0
        self.all_results = []
        
    def benchmark_config_detailed(self, M, K, N, config):
        """è¯¦ç»†çš„æ€§èƒ½æµ‹è¯•ï¼Œæ”¶é›†å¤šä¸ªç»Ÿè®¡æŒ‡æ ‡"""
        self.test_count += 1
        
        result = DetailedTestResult(
            shape=(M, K, N),
            hierarchy=config.hierarchy.name,
            mm1_overlap_ratio=config.mm1_overlap_ratio,
            mm1_prefetch_ratio=config.mm1_prefetch_ratio,
            mm2_overlap_ratio=config.mm2_overlap_ratio,
            mm2_prefetch_ratio=config.mm2_prefetch_ratio,
            rmsnorm_prefetch_ratio=config.rmsnorm_prefetch_ratio,
            latency_ms=0.0,
            throughput_gflops=0.0,
            latency_std_ms=0.0,
            successful=False,
            error_msg="",
            timestamp=datetime.now().isoformat(),
            min_latency_ms=float('inf'),
            max_latency_ms=0.0,
            median_latency_ms=0.0
        )
        
        try:
            # åˆ›å»ºæ¨¡å‹å’Œè¾“å…¥
            ffn = FeedForward(K, N, config)
            x = torch.randn((M, K)).to(device="cuda").to(dtype=torch.float8_e4m3fn)
            
            # Warmup
            for _ in range(self.warmup_iters):
                _ = ffn(x)
            torch.cuda.synchronize()
            
            # æ”¶é›†å¤šæ¬¡è¿è¡Œçš„å»¶è¿Ÿæ•°æ®
            latencies = []
            for _ in range(self.test_iters):
                start = time.perf_counter()
                _ = ffn(x)
                torch.cuda.synchronize()
                end = time.perf_counter()
                latencies.append((end - start) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            latencies = np.array(latencies)
            result.latency_ms = np.mean(latencies)
            result.latency_std_ms = np.std(latencies)
            result.min_latency_ms = np.min(latencies)
            result.max_latency_ms = np.max(latencies)
            result.median_latency_ms = np.median(latencies)
            
            # è®¡ç®—ååé‡
            flops = 4 * M * K * N
            result.throughput_gflops = flops / (result.latency_ms * 1e6)
            result.successful = True
            
        except Exception as e:
            result.error_msg = str(e)
            result.successful = False
        
        return result
    
    def run_comprehensive_test(self, shapes=None, sample_ratio=1.0):
        """è¿è¡Œå…¨é¢çš„æµ‹è¯•"""
        if shapes is None:
            shapes = self.test_shapes
        
        print("\n" + "="*120)
        print("COMPREHENSIVE FFN PERFORMANCE TESTING")
        print("="*120)
        print(f"Shapes to test: {shapes}")
        print(f"MM ratio values ({len(self.mm_ratio_values)}): {self.mm_ratio_values}")
        print(f"RMSNorm ratio values ({len(self.rmsnorm_ratio_values)}): {self.rmsnorm_ratio_values}")
        
        # è®¡ç®—æ€»é…ç½®æ•°
        total_configs_per_shape = (
            1 +  # NONE mode
            len(self.mm_ratio_values) ** 4 * len(self.rmsnorm_ratio_values)  # FREFTECH mode
        )
        total_configs = len(shapes) * total_configs_per_shape
        
        if sample_ratio < 1.0:
            sampled_configs = int(total_configs * sample_ratio)
            print(f"Sampling {sample_ratio*100:.0f}% of configurations: {sampled_configs}/{total_configs}")
        else:
            print(f"Total configurations to test: {total_configs}")
        
        print(f"Estimated time: {total_configs * 0.3 / 60:.1f} minutes")
        print("="*120)
        
        start_time = time.time()
        
        for shape_idx, (M, K, N) in enumerate(shapes):
            print(f"\n{'='*80}")
            print(f"Testing shape {shape_idx+1}/{len(shapes)}: M={M}, K={K}, N={N}")
            print(f"{'='*80}")
            
            # æµ‹è¯•NONEæ¨¡å¼
            config = FeedForwardPDLConfig()
            config.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.NONE
            
            print("\nTesting NONE mode...")
            result = self.benchmark_config_detailed(M, K, N, config)
            self.all_results.append(result)
            
            if result.successful:
                print(f"  âœ“ NONE: {result.throughput_gflops:.2f} GFLOPS, {result.latency_ms:.3f}Â±{result.latency_std_ms:.3f} ms")
            else:
                print(f"  âœ— NONE: Failed - {result.error_msg}")
            
            # æµ‹è¯•FREFTECHæ¨¡å¼çš„æ‰€æœ‰ç»„åˆ
            print("\nTesting FREFTECH mode combinations...")
            
            # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆ
            all_combinations = list(itertools.product(
                self.mm_ratio_values, self.mm_ratio_values,
                self.mm_ratio_values, self.mm_ratio_values,
                self.rmsnorm_ratio_values
            ))
            
            # å¦‚æœéœ€è¦é‡‡æ ·ï¼Œéšæœºé€‰æ‹©ä¸€éƒ¨åˆ†
            if sample_ratio < 1.0:
                num_samples = int(len(all_combinations) * sample_ratio)
                indices = np.random.choice(len(all_combinations), num_samples, replace=False)
                combinations_to_test = [all_combinations[i] for i in indices]
            else:
                combinations_to_test = all_combinations
            
            print(f"  Testing {len(combinations_to_test)} FREFTECH configurations...")
            
            for idx, (mm1_or, mm1_pr, mm2_or, mm2_pr, rms_pr) in enumerate(combinations_to_test):
                if idx % 100 == 0 and idx > 0:
                    elapsed = time.time() - start_time
                    eta = elapsed / self.test_count * (total_configs - self.test_count)
                    print(f"  Progress: {idx}/{len(combinations_to_test)} | "
                          f"Total: {self.test_count}/{total_configs} | "
                          f"ETA: {eta/60:.1f} min")
                
                config = FeedForwardPDLConfig()
                config.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.FREFTECH
                config.mm1_overlap_ratio = mm1_or
                config.mm1_prefetch_ratio = mm1_pr
                config.mm2_overlap_ratio = mm2_or
                config.mm2_prefetch_ratio = mm2_pr
                config.rmsnorm_prefetch_ratio = rms_pr
                
                result = self.benchmark_config_detailed(M, K, N, config)
                self.all_results.append(result)
                
                # æ‰“å°ç‰¹åˆ«å¥½çš„ç»“æœ
                if result.successful and result.throughput_gflops > 10000:  # é˜ˆå€¼å¯è°ƒæ•´
                    print(f"  ğŸ¯ High performance: {result.throughput_gflops:.2f} GFLOPS @ "
                          f"MM1({mm1_or:.1f},{mm1_pr:.1f}) MM2({mm2_or:.1f},{mm2_pr:.1f}) RMS({rms_pr:.1f})")
        
        total_time = time.time() - start_time
        print(f"\nâœ… Testing completed in {total_time:.2f} seconds ({total_time/60:.1f} minutes)")
        print(f"âœ… Total configurations tested: {self.test_count}")
        print(f"âœ… Successful tests: {sum(1 for r in self.all_results if r.successful)}")
        print(f"âœ… Failed tests: {sum(1 for r in self.all_results if not r.successful)}")
        
        return self.all_results
    
    def save_results(self, filename=None):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f'ffn_comprehensive_test_results_{timestamp}'
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame([{
            'shape': str(r.shape),
            'M': r.shape[0],
            'K': r.shape[1],
            'N': r.shape[2],
            'hierarchy': r.hierarchy,
            'mm1_overlap_ratio': r.mm1_overlap_ratio,
            'mm1_prefetch_ratio': r.mm1_prefetch_ratio,
            'mm2_overlap_ratio': r.mm2_overlap_ratio,
            'mm2_prefetch_ratio': r.mm2_prefetch_ratio,
            'rmsnorm_prefetch_ratio': r.rmsnorm_prefetch_ratio,
            'latency_ms': r.latency_ms,
            'latency_std_ms': r.latency_std_ms,
            'min_latency_ms': r.min_latency_ms,
            'max_latency_ms': r.max_latency_ms,
            'median_latency_ms': r.median_latency_ms,
            'throughput_gflops': r.throughput_gflops,
            'successful': r.successful,
            'error_msg': r.error_msg,
            'timestamp': r.timestamp
        } for r in self.all_results])
        
        # ä¿å­˜CSV
        df.to_csv(f'{filename}.csv', index=False)
        
        # ä¿å­˜JSONï¼ˆåŒ…å«æ›´å¤šå…ƒæ•°æ®ï¼‰
        metadata = {
            'test_info': {
                'mm_ratio_values': self.mm_ratio_values,
                'rmsnorm_ratio_values': self.rmsnorm_ratio_values,
                'test_shapes': self.test_shapes,
                'warmup_iters': self.warmup_iters,
                'test_iters': self.test_iters,
                'total_tests': self.test_count
            },
            'summary': {
                'total_configs': len(self.all_results),
                'successful_configs': sum(1 for r in self.all_results if r.successful),
                'failed_configs': sum(1 for r in self.all_results if not r.successful),
                'best_throughput': max((r.throughput_gflops for r in self.all_results if r.successful), default=0),
                'avg_throughput': np.mean([r.throughput_gflops for r in self.all_results if r.successful])
            }
        }
        
        with open(f'{filename}_metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"\nğŸ“ Results saved to:")
        print(f"   - {filename}.csv")
        print(f"   - {filename}_metadata.json")
        
        return df
    
    def analyze_results(self, df=None):
        """å…¨é¢åˆ†ææµ‹è¯•ç»“æœ"""
        if df is None:
            df = pd.DataFrame([{
                'shape': str(r.shape),
                'M': r.shape[0],
                'K': r.shape[1],
                'N': r.shape[2],
                'hierarchy': r.hierarchy,
                'mm1_overlap_ratio': r.mm1_overlap_ratio,
                'mm1_prefetch_ratio': r.mm1_prefetch_ratio,
                'mm2_overlap_ratio': r.mm2_overlap_ratio,
                'mm2_prefetch_ratio': r.mm2_prefetch_ratio,
                'rmsnorm_prefetch_ratio': r.rmsnorm_prefetch_ratio,
                'latency_ms': r.latency_ms,
                'throughput_gflops': r.throughput_gflops,
                'successful': r.successful
            } for r in self.all_results if r.successful])
        
        print("\n" + "="*120)
        print("COMPREHENSIVE ANALYSIS REPORT")
        print("="*120)
        
        # 1. åŸºæœ¬ç»Ÿè®¡
        print("\nğŸ“Š Basic Statistics:")
        print(f"Total successful configurations: {len(df)}")
        print(f"Unique shapes tested: {df['shape'].nunique()}")
        print(f"Average throughput: {df['throughput_gflops'].mean():.2f} Â± {df['throughput_gflops'].std():.2f} GFLOPS")
        print(f"Max throughput: {df['throughput_gflops'].max():.2f} GFLOPS")
        print(f"Min throughput: {df['throughput_gflops'].min():.2f} GFLOPS")
        
        # 2. NONE vs FREFTECHå¯¹æ¯”
        print("\nğŸ“Š NONE vs FREFTECH Comparison:")
        none_df = df[df['hierarchy'] == 'NONE']
        prefetch_df = df[df['hierarchy'] == 'FREFTECH']
        
        print("-"*100)
        print(f"{'Shape':<20} {'NONE (GFLOPS)':<15} {'FREFTECH Best':<15} {'FREFTECH Avg':<15} {'Improvement'}")
        print("-"*100)
        
        for shape in df['shape'].unique():
            shape_none = none_df[none_df['shape'] == shape]
            shape_prefetch = prefetch_df[prefetch_df['shape'] == shape]
            
            if len(shape_none) > 0 and len(shape_prefetch) > 0:
                none_perf = shape_none['throughput_gflops'].iloc[0]
                prefetch_best = shape_prefetch['throughput_gflops'].max()
                prefetch_avg = shape_prefetch['throughput_gflops'].mean()
                improvement = (prefetch_best - none_perf) / none_perf
                
                print(f"{shape:<20} {none_perf:<15.2f} {prefetch_best:<15.2f} {prefetch_avg:<15.2f} {improvement:>+.1%}")
        
        # 3. å‚æ•°æ•æ„Ÿæ€§åˆ†æ
        print("\nğŸ“Š Parameter Sensitivity Analysis:")
        
        if len(prefetch_df) > 0:
            params = ['mm1_overlap_ratio', 'mm1_prefetch_ratio', 
                     'mm2_overlap_ratio', 'mm2_prefetch_ratio', 
                     'rmsnorm_prefetch_ratio']
            
            print("\nCorrelation with throughput:")
            for param in params:
                corr = prefetch_df[param].corr(prefetch_df['throughput_gflops'])
                print(f"  {param}: {corr:.3f}")
            
            # 4. æœ€ä½³é…ç½®æ¨¡å¼
            print("\nğŸ“Š Best Configuration Patterns:")
            
            # å¯¹æ¯ä¸ªshapeæ‰¾å‡ºtop 5é…ç½®
            for shape in df['shape'].unique():
                shape_prefetch = prefetch_df[prefetch_df['shape'] == shape]
                if len(shape_prefetch) > 0:
                    print(f"\nShape {shape} - Top 5 configurations:")
                    top5 = shape_prefetch.nlargest(5, 'throughput_gflops')
                    
                    for idx, row in top5.iterrows():
                        print(f"  {row['throughput_gflops']:.2f} GFLOPS: "
                              f"MM1({row['mm1_overlap_ratio']:.1f},{row['mm1_prefetch_ratio']:.1f}) "
                              f"MM2({row['mm2_overlap_ratio']:.1f},{row['mm2_prefetch_ratio']:.1f}) "
                              f"RMS({row['rmsnorm_prefetch_ratio']:.1f})")
            
            # 5. å‚æ•°å€¼åˆ†å¸ƒ
            print("\nğŸ“Š Parameter Value Distribution in Top 10% Configs:")
            
            # æ‰¾å‡ºæ€§èƒ½å‰10%çš„é…ç½®
            threshold = prefetch_df['throughput_gflops'].quantile(0.9)
            top_configs = prefetch_df[prefetch_df['throughput_gflops'] >= threshold]
            
            for param in params:
                value_counts = top_configs[param].value_counts().head(5)
                print(f"\n{param} (top values in best configs):")
                for value, count in value_counts.items():
                    percentage = count / len(top_configs) * 100
                    print(f"  {value:>4.1f}: {count:>3} ({percentage:>5.1f}%)")
            
            # 6. ç¨³å®šæ€§åˆ†æï¼ˆå¦‚æœæœ‰æ ‡å‡†å·®æ•°æ®ï¼‰
            if 'latency_std_ms' in df.columns:
                print("\nğŸ“Š Stability Analysis:")
                print("Configurations with lowest latency variance:")
                stable_configs = df.nsmallest(10, 'latency_std_ms')
                for _, row in stable_configs.iterrows():
                    cv = row['latency_std_ms'] / row['latency_ms'] * 100  # å˜å¼‚ç³»æ•°
                    print(f"  Shape {row['shape']}: {row['latency_ms']:.3f}Â±{row['latency_std_ms']:.3f}ms "
                          f"(CV={cv:.1f}%), {row['throughput_gflops']:.2f} GFLOPS")
        
        return df
    
    def generate_heatmaps(self, df=None, save_path='heatmaps'):
        """ç”Ÿæˆçƒ­åŠ›å›¾åˆ†æ"""
        if df is None:
            df = pd.DataFrame([{
                'shape': str(r.shape),
                'hierarchy': r.hierarchy,
                'mm1_overlap_ratio': r.mm1_overlap_ratio,
                'mm1_prefetch_ratio': r.mm1_prefetch_ratio,
                'mm2_overlap_ratio': r.mm2_overlap_ratio,
                'mm2_prefetch_ratio': r.mm2_prefetch_ratio,
                'rmsnorm_prefetch_ratio': r.rmsnorm_prefetch_ratio,
                'throughput_gflops': r.throughput_gflops,
                'successful': r.successful
            } for r in self.all_results if r.successful])
        
        prefetch_df = df[df['hierarchy'] == 'FREFTECH']
        
        if len(prefetch_df) == 0:
            print("No FREFTECH data to visualize")
            return
        
        # ä¸ºæ¯ä¸ªshapeç”Ÿæˆçƒ­åŠ›å›¾
        for shape in prefetch_df['shape'].unique():
            shape_df = prefetch_df[prefetch_df['shape'] == shape]
            
            # MM1å‚æ•°çƒ­åŠ›å›¾
            plt.figure(figsize=(10, 8))
            pivot = shape_df.pivot_table(
                values='throughput_gflops',
                index='mm1_overlap_ratio',
                columns='mm1_prefetch_ratio',
                aggfunc='mean'
            )
            sns.heatmap(pivot, annot=True, fmt='.0f', cmap='YlOrRd')
            plt.title(f'MM1 Parameters Heatmap - Shape {shape}')
            plt.tight_layout()
            plt.savefig(f'{save_path}_mm1_{shape}.png')
            plt.close()
            
            # MM2å‚æ•°çƒ­åŠ›å›¾
            plt.figure(figsize=(10, 8))
            pivot = shape_df.pivot_table(
                values='throughput_gflops',
                index='mm2_overlap_ratio',
                columns='mm2_prefetch_ratio',
                aggfunc='mean'
            )
            sns.heatmap(pivot, annot=True, fmt='.0f', cmap='YlOrRd')
            plt.title(f'MM2 Parameters Heatmap - Shape {shape}')
            plt.tight_layout()
            plt.savefig(f'{save_path}_mm2_{shape}.png')
            plt.close()
            
        print(f"\nğŸ“Š Heatmaps saved with prefix: {save_path}")
    
    def find_optimal_configs(self, df=None):
        """ä¸ºæ¯ä¸ªshapeæ‰¾å‡ºæœ€ä¼˜é…ç½®"""
        if df is None:
            df = pd.DataFrame([{
                'shape': str(r.shape),
                'hierarchy': r.hierarchy,
                'mm1_overlap_ratio': r.mm1_overlap_ratio,
                'mm1_prefetch_ratio': r.mm1_prefetch_ratio,
                'mm2_overlap_ratio': r.mm2_overlap_ratio,
                'mm2_prefetch_ratio': r.mm2_prefetch_ratio,
                'rmsnorm_prefetch_ratio': r.rmsnorm_prefetch_ratio,
                'throughput_gflops': r.throughput_gflops,
                'latency_ms': r.latency_ms,
                'successful': r.successful
            } for r in self.all_results if r.successful])
        
        print("\n" + "="*120)
        print("OPTIMAL CONFIGURATIONS")
        print("="*120)
        
        optimal_configs = {}
        
        for shape in df['shape'].unique():
            shape_df = df[df['shape'] == shape]
            
            # NONEæ¨¡å¼æ€§èƒ½
            none_df = shape_df[shape_df['hierarchy'] == 'NONE']
            none_perf = none_df['throughput_gflops'].iloc[0] if len(none_df) > 0 else 0
            
            # æœ€ä½³FREFTECHé…ç½®
            prefetch_df = shape_df[shape_df['hierarchy'] == 'FREFTECH']
            if len(prefetch_df) > 0:
                best_idx = prefetch_df['throughput_gflops'].idxmax()
                best_config = prefetch_df.loc[best_idx]
                
                optimal_configs[shape] = {
                    'none_throughput': none_perf,
                    'best_throughput': best_config['throughput_gflops'],
                    'improvement': (best_config['throughput_gflops'] - none_perf) / none_perf if none_perf > 0 else 0,
                    'config': {
                        'mm1_overlap_ratio': best_config['mm1_overlap_ratio'],
                        'mm1_prefetch_ratio': best_config['mm1_prefetch_ratio'],
                        'mm2_overlap_ratio': best_config['mm2_overlap_ratio'],
                        'mm2_prefetch_ratio': best_config['mm2_prefetch_ratio'],
                        'rmsnorm_prefetch_ratio': best_config['rmsnorm_prefetch_ratio']
                    }
                }
                
                print(f"\nğŸ¯ Shape {shape}:")
                print(f"   NONE: {none_perf:.2f} GFLOPS")
                print(f"   Best: {best_config['throughput_gflops']:.2f} GFLOPS "
                      f"(+{optimal_configs[shape]['improvement']:.1%})")
                print(f"   Config: MM1({best_config['mm1_overlap_ratio']:.1f},{best_config['mm1_prefetch_ratio']:.1f}) "
                      f"MM2({best_config['mm2_overlap_ratio']:.1f},{best_config['mm2_prefetch_ratio']:.1f}) "
                      f"RMS({best_config['rmsnorm_prefetch_ratio']:.1f})")
                
                # ç”Ÿæˆå¯ç›´æ¥ä½¿ç”¨çš„ä»£ç 
                print(f"\n   # Code for shape {shape}:")
                print(f"   config = FeedForwardPDLConfig()")
                print(f"   config.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.FREFTECH")
                print(f"   config.mm1_overlap_ratio = {best_config['mm1_overlap_ratio']}")
                print(f"   config.mm1_prefetch_ratio = {best_config['mm1_prefetch_ratio']}")
                print(f"   config.mm2_overlap_ratio = {best_config['mm2_overlap_ratio']}")
                print(f"   config.mm2_prefetch_ratio = {best_config['mm2_prefetch_ratio']}")
                print(f"   config.rmsnorm_prefetch_ratio = {best_config['rmsnorm_prefetch_ratio']}")
        
        return optimal_configs

if __name__ == "__main__":
    tester = ComprehensiveFFNTester()
    
    # è¿è¡Œæ¨¡å¼é€‰æ‹©
    mode = "sample"  # "full", "sample", "single_shape"
    
    if mode == "full":
        # å®Œæ•´æµ‹è¯•æ‰€æœ‰é…ç½®
        results = tester.run_comprehensive_test()
        
    elif mode == "sample":
        # é‡‡æ ·æµ‹è¯•ï¼ˆæµ‹è¯•20%çš„é…ç½®ï¼‰
        results = tester.run_comprehensive_test(sample_ratio=0.2)
        
    elif mode == "single_shape":
        # æµ‹è¯•å•ä¸ªshapeçš„æ‰€æœ‰é…ç½®
        single_shape = [(128, 2048, 4096)]
        results = tester.run_comprehensive_test(shapes=single_shape)
    
    # ä¿å­˜ç»“æœ
    df = tester.save_results()
    
    # å…¨é¢åˆ†æ
    tester.analyze_results(df)
    
    # æ‰¾å‡ºæœ€ä¼˜é…ç½®
    optimal_configs = tester.find_optimal_configs(df)
    
    # ç”Ÿæˆå¯è§†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
    try:
        tester.generate_heatmaps(df)
    except Exception as e:
        print(f"Warning: Could not generate heatmaps: {e}")
    
    # é¢å¤–çš„ç»Ÿè®¡åˆ†æ
    print("\n" + "="*120)
    print("ADDITIONAL STATISTICAL ANALYSIS")
    print("="*120)
    
    # åˆ†æå¤±è´¥çš„é…ç½®
    failed_results = [r for r in tester.all_results if not r.successful]
    if failed_results:
        print(f"\nâš ï¸  Failed configurations: {len(failed_results)}")
        # åˆ†æå¤±è´¥æ¨¡å¼
        failed_patterns = {}
        for result in failed_results:
            key = f"MM1({result.mm1_overlap_ratio},{result.mm1_prefetch_ratio})"
            failed_patterns[key] = failed_patterns.get(key, 0) + 1
        
        print("Most common failure patterns:")
        for pattern, count in sorted(failed_patterns.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  {pattern}: {count} failures")
    
    # å‚æ•°äº¤äº’æ•ˆåº”åˆ†æ
    if len(df) > 100:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®
        print("\nğŸ“Š Parameter Interaction Analysis:")
        
        prefetch_df = df[df['hierarchy'] == 'FREFTECH']
        if len(prefetch_df) > 0:
            # åˆ†æå‚æ•°ä¹‹é—´çš„äº¤äº’
            from sklearn.preprocessing import PolynomialFeatures
            from sklearn.linear_model import LinearRegression
            from sklearn.metrics import r2_score
            
            try:
                # å‡†å¤‡æ•°æ®
                param_cols = ['mm1_overlap_ratio', 'mm1_prefetch_ratio', 
                             'mm2_overlap_ratio', 'mm2_prefetch_ratio', 
                             'rmsnorm_prefetch_ratio']
                X = prefetch_df[param_cols].values
                y = prefetch_df['throughput_gflops'].values
                
                # åˆ›å»ºäºŒé˜¶äº¤äº’ç‰¹å¾
                poly = PolynomialFeatures(degree=2, include_bias=False)
                X_poly = poly.fit_transform(X)
                
                # æ‹Ÿåˆçº¿æ€§æ¨¡å‹
                model = LinearRegression()
                model.fit(X_poly, y)
                y_pred = model.predict(X_poly)
                r2 = r2_score(y, y_pred)
                
                print(f"\nPolynomial regression RÂ²: {r2:.3f}")
                
                # è·å–ç‰¹å¾åç§°å’Œç³»æ•°
                feature_names = poly.get_feature_names_out(param_cols)
                coefficients = model.coef_
                
                # æ‰¾å‡ºæœ€é‡è¦çš„äº¤äº’é¡¹
                interactions = [(name, coef) for name, coef in zip(feature_names, coefficients) 
                               if ' ' in name]  # äº¤äº’é¡¹åŒ…å«ç©ºæ ¼
                interactions.sort(key=lambda x: abs(x[1]), reverse=True)
                
                print("\nTop 10 most important parameter interactions:")
                for name, coef in interactions[:10]:
                    print(f"  {name}: {coef:.2f}")
                
            except Exception as e:
                print(f"Could not perform interaction analysis: {e}")
    
    # ç”Ÿæˆæ€§èƒ½é¢„æµ‹æ¨¡å‹
    print("\nğŸ“Š Performance Prediction Model:")
    
    try:
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.model_selection import train_test_split
        
        prefetch_df = df[df['hierarchy'] == 'FREFTECH']
        if len(prefetch_df) > 100:
            # å‡†å¤‡ç‰¹å¾
            feature_cols = ['M', 'K', 'N', 'mm1_overlap_ratio', 'mm1_prefetch_ratio',
                           'mm2_overlap_ratio', 'mm2_prefetch_ratio', 'rmsnorm_prefetch_ratio']
            X = prefetch_df[feature_cols]
            y = prefetch_df['throughput_gflops']
            
            # åˆ†å‰²æ•°æ®
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # è®­ç»ƒéšæœºæ£®æ—
            rf = RandomForestRegressor(n_estimators=100, random_state=42)
            rf.fit(X_train, y_train)
            
            # è¯„ä¼°
            train_score = rf.score(X_train, y_train)
            test_score = rf.score(X_test, y_test)
            
            print(f"Random Forest model performance:")
            print(f"  Training RÂ²: {train_score:.3f}")
            print(f"  Testing RÂ²: {test_score:.3f}")
            
            # ç‰¹å¾é‡è¦æ€§
            feature_importance = pd.DataFrame({
                'feature': feature_cols,
                'importance': rf.feature_importances_
            }).sort_values('importance', ascending=False)
            
            print("\nFeature importance:")
            for _, row in feature_importance.iterrows():
                print(f"  {row['feature']}: {row['importance']:.3f}")
            
    except Exception as e:
        print(f"Could not build prediction model: {e}")
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    print("\n" + "="*120)
    print("OPTIMIZATION RECOMMENDATIONS")
    print("="*120)
    
    if optimal_configs:
        # åˆ†ææœ€ä¼˜é…ç½®çš„å…±åŒç‰¹å¾
        best_configs_data = []
        for shape, config_info in optimal_configs.items():
            config = config_info['config']
            config['shape'] = shape
            config['improvement'] = config_info['improvement']
            best_configs_data.append(config)
        
        best_df = pd.DataFrame(best_configs_data)
        
        print("\nğŸ’¡ Common patterns in optimal configurations:")
        
        # ç»Ÿè®¡æ¯ä¸ªå‚æ•°çš„æœ€å¸¸è§å€¼
        for param in ['mm1_overlap_ratio', 'mm1_prefetch_ratio', 
                     'mm2_overlap_ratio', 'mm2_prefetch_ratio', 
                     'rmsnorm_prefetch_ratio']:
            value_counts = best_df[param].value_counts()
            most_common = value_counts.index[0]
            frequency = value_counts.iloc[0] / len(best_df)
            
            print(f"\n{param}:")
            print(f"  Most common optimal value: {most_common:.1f} ({frequency:.0%} of shapes)")
            print(f"  Range: [{best_df[param].min():.1f}, {best_df[param].max():.1f}]")
            print(f"  Mean: {best_df[param].mean():.2f}")
        
        # åŸºäºæ”¹è¿›å¹…åº¦åˆ†ç»„
        print("\nğŸ’¡ Recommendations by improvement level:")
        
        high_improvement = best_df[best_df['improvement'] > 0.2]
        medium_improvement = best_df[(best_df['improvement'] > 0.1) & (best_df['improvement'] <= 0.2)]
        low_improvement = best_df[best_df['improvement'] <= 0.1]
        
        if len(high_improvement) > 0:
            print(f"\nHigh improvement shapes (>20%):")
            for _, row in high_improvement.iterrows():
                print(f"  {row['shape']}: +{row['improvement']:.1%}")
            print("  Recommended strategy: Always use FREFTECH with optimized ratios")
        
        if len(medium_improvement) > 0:
            print(f"\nMedium improvement shapes (10-20%):")
            for _, row in medium_improvement.iterrows():
                print(f"  {row['shape']}: +{row['improvement']:.1%}")
            print("  Recommended strategy: Use FREFTECH for performance-critical paths")
        
        if len(low_improvement) > 0:
            print(f"\nLow improvement shapes (<10%):")
            for _, row in low_improvement.iterrows():
                print(f"  {row['shape']}: +{row['improvement']:.1%}")
            print("  Recommended strategy: Consider workload characteristics before enabling FREFTECH")
    
    # ç”Ÿæˆå¿«é€ŸæŸ¥æ‰¾è¡¨
    print("\n" + "="*120)
    print("QUICK REFERENCE TABLE")
    print("="*120)
    
    print("\n```python")
    print("# Optimal FFN configurations for different shapes")
    print("OPTIMAL_FFN_CONFIGS = {")
    
    for shape, config_info in optimal_configs.items():
        M, K, N = eval(shape)  # ä»å­—ç¬¦ä¸²è½¬å›å…ƒç»„
        config = config_info['config']
        print(f"    ({M}, {K}, {N}): {{")
        print(f"        'mm1_overlap_ratio': {config['mm1_overlap_ratio']},")
        print(f"        'mm1_prefetch_ratio': {config['mm1_prefetch_ratio']},")
        print(f"        'mm2_overlap_ratio': {config['mm2_overlap_ratio']},")
        print(f"        'mm2_prefetch_ratio': {config['mm2_prefetch_ratio']},")
        print(f"        'rmsnorm_prefetch_ratio': {config['rmsnorm_prefetch_ratio']},")
        print(f"        'expected_throughput': {config_info['best_throughput']:.2f},")
        print(f"        'improvement': {config_info['improvement']:.1%}")
        print(f"    }},")
    
    print("}")
    print("\n# Usage:")
    print("# shape = (M, K, N)")
    print("# if shape in OPTIMAL_FFN_CONFIGS:")
    print("#     config = FeedForwardPDLConfig()")
    print("#     config.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.FREFTECH")
    print("#     for key, value in OPTIMAL_FFN_CONFIGS[shape].items():")
    print("#         if hasattr(config, key):")
    print("#             setattr(config, key, value)")
    print("```")
    
    # æ€»ç»“
    print("\n" + "="*120)
    print("EXECUTIVE SUMMARY")
    print("="*120)
    
    total_time = sum(r.latency_ms for r in tester.all_results if r.successful)
    
    print(f"\nğŸ“Š Test Summary:")
    print(f"   - Total configurations tested: {tester.test_count}")
    print(f"   - Successful tests: {sum(1 for r in tester.all_results if r.successful)}")
    print(f"   - Failed tests: {sum(1 for r in tester.all_results if not r.successful)}")
    print(f"   - Total test time: {total_time/1000:.1f} seconds")
    print(f"   - Shapes tested: {len(tester.test_shapes)}")
    
    if optimal_configs:
        improvements = [config['improvement'] for config in optimal_configs.values()]
        print(f"\nğŸ“ˆ Performance Improvements:")
        print(f"   - Average improvement: {np.mean(improvements):.1%}")
        print(f"   - Maximum improvement: {np.max(improvements):.1%}")
        print(f"   - Minimum improvement: {np.min(improvements):.1%}")
        
        # æ‰¾å‡ºæœ€ä½³æ•´ä½“é…ç½®
        all_improvements = []
        for param in ['mm1_overlap_ratio', 'mm1_prefetch_ratio', 
                     'mm2_overlap_ratio', 'mm2_prefetch_ratio', 
                     'rmsnorm_prefetch_ratio']:
            values = [config['config'][param] for config in optimal_configs.values()]
            most_common = max(set(values), key=values.count)
            all_improvements.append((param, most_common))
        
        print(f"\nğŸ¯ Universal Good Starting Point:")
        print("   config = FeedForwardPDLConfig()")
        print("   config.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.FREFTECH")
        for param, value in all_improvements:
            print(f"   config.{param} = {value}")
        
        print(f"\nğŸ’¡ Key Insights:")
        print("   1. FREFTECH mode consistently outperforms NONE mode across all tested shapes")
        print("   2. Optimal ratio values are shape-dependent but show consistent patterns")
        print("   3. MM operations benefit significantly from overlap/prefetch optimizations")
        print("   4. RMSNorm prefetch ratio has moderate but consistent impact")
        print("   5. Parameter interactions are important for achieving peak performance")
    
    print("\n" + "="*120)
    print("END OF COMPREHENSIVE ANALYSIS")
    print("="*120)


# è¾…åŠ©å‡½æ•°ï¼šä»ä¿å­˜çš„CSVæ–‡ä»¶åŠ è½½ç»“æœè¿›è¡Œåˆ†æ
def analyze_saved_results(csv_file):
    """åˆ†æä¹‹å‰ä¿å­˜çš„æµ‹è¯•ç»“æœ"""
    print(f"Loading results from {csv_file}...")
    df = pd.read_csv(csv_file)
    
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„testerå¯¹è±¡ç”¨äºåˆ†æ
    tester = ComprehensiveFFNTester()
    
    # åˆ†æç»“æœ
    tester.analyze_results(df)
    
    # æ‰¾å‡ºæœ€ä¼˜é…ç½®
    optimal_configs = tester.find_optimal_configs(df)
    
    # ç”Ÿæˆå¯è§†åŒ–
    try:
        tester.generate_heatmaps(df, save_path=f'{csv_file}_heatmaps')
    except Exception as e:
        print(f"Warning: Could not generate heatmaps: {e}")
    
    return df, optimal_configs


# å¿«é€ŸåŸºå‡†æµ‹è¯•å‡½æ•°
def quick_benchmark(M, K, N, config=None):
    """å¯¹ç‰¹å®šshapeå’Œé…ç½®è¿›è¡Œå¿«é€ŸåŸºå‡†æµ‹è¯•"""
    if config is None:
        config = FeedForwardPDLConfig()
        config.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.NONE
    
    tester = ComprehensiveFFNTester()
    tester.warmup_iters = 20
    tester.test_iters = 50
    
    result = tester.benchmark_config_detailed(M, K, N, config)
    
    if result.successful:
        print(f"\nâœ“ Shape ({M}, {K}, {N}) - {config.hierarchy.name} mode:")
        print(f"  Throughput: {result.throughput_gflops:.2f} GFLOPS")
        print(f"  Latency: {result.latency_ms:.3f} Â± {result.latency_std_ms:.3f} ms")
        print(f"  Min/Max: {result.min_latency_ms:.3f}/{result.max_latency_ms:.3f} ms")
    else:
        print(f"\nâœ— Shape ({M}, {K}, {N}) - Failed: {result.error_msg}")
    
    return result


# å‚æ•°æ‰«æå‡½æ•°
def parameter_sweep(M, K, N, param_name, param_values):
    """å¯¹å•ä¸ªå‚æ•°è¿›è¡Œæ‰«ææµ‹è¯•"""
    results = []
    tester = ComprehensiveFFNTester()
    tester.warmup_iters = 10
    tester.test_iters = 50
    
    print(f"\nParameter sweep for {param_name} on shape ({M}, {K}, {N}):")
    print("-" * 50)
    
    for value in param_values:
        config = FeedForwardPDLConfig()
        config.hierarchy = cutlass_gemm_with_prefetch.KernelOverlapHierarchy.FREFTECH
        setattr(config, param_name, value)
        
        result = tester.benchmark_config_detailed(M, K, N, config)
        
        if result.successful:
            print(f"{param_name}={value:>4.1f}: {result.throughput_gflops:>8.2f} GFLOPS")
            results.append((value, result.throughput_gflops))
        else:
            print(f"{param_name}={value:>4.1f}: Failed")
    
    return results